"""
é€šç”¨è§†é¢‘ä¸‹è½½å™¨ - æ”¯æŒå¤šå¹³å°
ä½¿ç”¨ yt-dlp å®ç°ï¼Œæ”¯æŒ Instagramã€YouTubeã€Twitter/Xã€Facebook ç­‰ 1000+ å¹³å°
æŠ–éŸ³ä½¿ç”¨ curl_cffi æ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®ç§»åŠ¨ç«¯é¡µé¢
"""
import os
import time
import uuid
import re
import json
from typing import Optional, Dict, Any, Tuple
from urllib.parse import unquote

try:
    import yt_dlp
except ImportError:
    yt_dlp = None

try:
    from curl_cffi import requests as cffi_requests
    _has_curl_cffi = True
except ImportError:
    _has_curl_cffi = False
    import requests


class UniversalDownloader:
    """é€šç”¨è§†é¢‘ä¸‹è½½å™¨ï¼Œæ”¯æŒå¤šå¹³å°"""
    
    # æ”¯æŒçš„å¹³å°åŠå…¶ URL åŒ¹é…æ¨¡å¼
    PLATFORMS = {
        'tiktok': {
            'name': 'TikTok',
            'patterns': [
                r'tiktok\.com',
                r'vm\.tiktok\.com',
            ],
            'icon': 'ğŸµ',
        },
        'douyin': {
            'name': 'æŠ–éŸ³',
            'patterns': [
                r'douyin\.com',
                r'v\.douyin\.com',
                r'iesdouyin\.com',
            ],
            'icon': 'ğŸ¶',
        },
        'instagram': {
            'name': 'Instagram',
            'patterns': [
                r'instagram\.com',
                r'instagr\.am',
            ],
            'icon': 'ğŸ“¸',
        },
        'youtube': {
            'name': 'YouTube',
            'patterns': [
                r'youtube\.com',
                r'youtu\.be',
            ],
            'icon': 'ğŸ¬',
        },
        'twitter': {
            'name': 'Twitter/X',
            'patterns': [
                r'twitter\.com',
                r'x\.com',
            ],
            'icon': 'ğŸ¦',
        },
        'facebook': {
            'name': 'Facebook',
            'patterns': [
                r'facebook\.com',
                r'fb\.watch',
                r'fb\.com',
            ],
            'icon': 'ğŸ“˜',
        },
        'bilibili': {
            'name': 'Bç«™',
            'patterns': [
                r'bilibili\.com',
                r'b23\.tv',
            ],
            'icon': 'ğŸ“º',
        },
        'weibo': {
            'name': 'å¾®åš',
            'patterns': [
                r'weibo\.com',
                r'weibo\.cn',
            ],
            'icon': 'ğŸ”´',
        },
    }
    
    def __init__(self, download_dir: str = "downloads") -> None:
        self.download_dir = download_dir
        os.makedirs(self.download_dir, exist_ok=True)
    
    def detect_platform(self, url: str) -> Tuple[str, str]:
        """
        æ£€æµ‹ URL å¯¹åº”çš„å¹³å°
        è¿”å›: (platform_key, platform_name)
        """
        if not url:
            return 'unknown', 'æœªçŸ¥å¹³å°'
        
        url_lower = url.lower()
        for platform_key, platform_info in self.PLATFORMS.items():
            for pattern in platform_info['patterns']:
                if re.search(pattern, url_lower):
                    return platform_key, platform_info['name']
        
        return 'other', 'å…¶ä»–å¹³å°'
    
    def get_supported_platforms(self) -> list:
        """è·å–æ‰€æœ‰æ”¯æŒçš„å¹³å°åˆ—è¡¨"""
        return [
            {
                'key': key,
                'name': info['name'],
                'icon': info['icon'],
            }
            for key, info in self.PLATFORMS.items()
        ]
    
    def extract_url_from_text(self, text: str) -> str:
        """
        ä»åˆ†äº«æ–‡æœ¬ä¸­æå–è§†é¢‘ URL
        æ”¯æŒæŠ–éŸ³ã€TikTokã€Instagram ç­‰å¹³å°çš„åˆ†äº«æ–‡æœ¬æ ¼å¼
        """
        if not text:
            return ""
        
        # é€šç”¨ URL æ­£åˆ™è¡¨è¾¾å¼
        url_patterns = [
            # æŠ–éŸ³çŸ­é“¾æ¥
            r'https?://v\.douyin\.com/[A-Za-z0-9]+/?',
            # æŠ–éŸ³å®Œæ•´é“¾æ¥
            r'https?://www\.douyin\.com/video/\d+',
            # TikTok çŸ­é“¾æ¥
            r'https?://vm\.tiktok\.com/[A-Za-z0-9]+/?',
            r'https?://www\.tiktok\.com/t/[A-Za-z0-9]+/?',
            # TikTok å®Œæ•´é“¾æ¥
            r'https?://www\.tiktok\.com/@[^/]+/video/\d+',
            # Instagram
            r'https?://(?:www\.)?instagram\.com/(?:p|reel)/[A-Za-z0-9_-]+/?',
            # YouTube
            r'https?://(?:www\.)?youtube\.com/watch\?v=[A-Za-z0-9_-]+',
            r'https?://youtu\.be/[A-Za-z0-9_-]+',
            r'https?://(?:www\.)?youtube\.com/shorts/[A-Za-z0-9_-]+',
            # Twitter/X
            r'https?://(?:www\.)?(?:twitter|x)\.com/[^/]+/status/\d+',
            # Facebook
            r'https?://(?:www\.)?facebook\.com/.+/videos/\d+',
            r'https?://fb\.watch/[A-Za-z0-9]+/?',
            # Bilibili
            r'https?://(?:www\.)?bilibili\.com/video/[A-Za-z0-9]+',
            r'https?://b23\.tv/[A-Za-z0-9]+',
            # å¾®åš
            r'https?://(?:www\.)?weibo\.com/tv/show/\d+',
            r'https?://(?:m\.)?weibo\.cn/[^\s]+',
            # é€šç”¨ HTTPS é“¾æ¥ï¼ˆä½œä¸ºåå¤‡ï¼‰
            r'https?://[^\s<>"]+',
        ]
        
        for pattern in url_patterns:
            match = re.search(pattern, text)
            if match:
                url = match.group(0)
                # æ¸…ç† URL æœ«å°¾å¯èƒ½çš„æ ‡ç‚¹ç¬¦å·
                url = url.rstrip('.,;:!?\'\"')
                print(f"ä»æ–‡æœ¬ä¸­æå–åˆ° URL: {url}")
                return url
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½• URL æ¨¡å¼ï¼Œè¿”å›åŸå§‹æ–‡æœ¬ï¼ˆå¯èƒ½æœ¬èº«å°±æ˜¯ URLï¼‰
        return text.strip()
    
    def _resolve_douyin_url(self, url: str) -> str:
        """è§£ææŠ–éŸ³çŸ­é“¾æ¥ï¼Œè·å–è§†é¢‘ID"""
        try:
            if _has_curl_cffi:
                session = cffi_requests.Session(impersonate='chrome120')
                resp = session.get(url, allow_redirects=True)
            else:
                resp = requests.get(url, allow_redirects=True, headers={
                    'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)'
                })
            final_url = str(resp.url)
            match = re.search(r'/video/(\d+)', final_url)
            if match:
                return match.group(1)
        except Exception as e:
            print(f"[æŠ–éŸ³] è§£æçŸ­é“¾æ¥å¤±è´¥: {e}")
        return None
    
    def _get_douyin_video_info(self, url: str) -> Dict[str, Any]:
        """
        é€šè¿‡ç§»åŠ¨ç«¯é¡µé¢è·å–æŠ–éŸ³è§†é¢‘ä¿¡æ¯
        ä½¿ç”¨ curl_cffi æ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—® m.douyin.com
        """
        # æå–è§†é¢‘ID
        video_id = None
        match = re.search(r'/video/(\d+)', url)
        if match:
            video_id = match.group(1)
        else:
            video_id = self._resolve_douyin_url(url)
        
        if not video_id:
            return self._error_response("æ— æ³•æå–æŠ–éŸ³è§†é¢‘ID")
        
        print(f"[æŠ–éŸ³] è§†é¢‘ID: {video_id}")
        
        try:
            # è®¿é—®ç§»åŠ¨ç«¯é¡µé¢
            if _has_curl_cffi:
                session = cffi_requests.Session(impersonate='chrome120')
            else:
                session = None
                
            mobile_url = f'https://m.douyin.com/share/video/{video_id}'
            headers = {
                'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9',
            }
            
            if session:
                mobile_resp = session.get(mobile_url, headers=headers)
            else:
                mobile_resp = requests.get(mobile_url, headers=headers)
            
            html = mobile_resp.text
            print(f"[æŠ–éŸ³] è·å–ç§»åŠ¨ç«¯é¡µé¢: {len(html)} å­—èŠ‚")
            
            # ä» script æ ‡ç­¾ä¸­æå–è§†é¢‘æ•°æ®
            scripts = re.findall(r'<script[^>]*>(.*?)</script>', html, re.DOTALL)
            
            for script in scripts:
                if 'play_addr' not in script:
                    continue
                
                # æå–å„å­—æ®µ
                title = ''
                author = ''
                video_url = ''
                cover_url = ''
                duration = 0
                like_count = 0
                comment_count = 0
                share_count = 0
                
                # æ ‡é¢˜
                desc_match = re.search(r'"desc"\s*:\s*"((?:[^"\\]|\\.)*)"', script)
                if desc_match:
                    title = self._decode_unicode_text(desc_match.group(1))
                
                # ä½œè€…
                nick_match = re.search(r'"nickname"\s*:\s*"((?:[^"\\]|\\.)*)"', script)
                if nick_match:
                    author = self._decode_unicode_text(nick_match.group(1))
                
                # è§†é¢‘æ’­æ”¾åœ°å€
                play_match = re.search(r'"play_addr"\s*:\s*\{[^}]*"url_list"\s*:\s*\["((?:[^"\\]|\\.)*)"', script)
                if play_match:
                    video_url = play_match.group(1).replace('\\u002F', '/').replace('playwm', 'play')
                
                # å°é¢å›¾
                cover_match = re.search(r'"cover"\s*:\s*\{[^}]*"url_list"\s*:\s*\["((?:[^"\\]|\\.)*)"', script)
                if cover_match:
                    cover_url = cover_match.group(1).replace('\\u002F', '/')
                
                # æ—¶é•¿
                dur_match = re.search(r'"duration"\s*:\s*(\d+)', script)
                if dur_match:
                    duration = int(dur_match.group(1))
                    # æŠ–éŸ³durationæ˜¯æ¯«ç§’ï¼Œè½¬ä¸ºç§’
                    if duration > 1000:
                        duration = duration // 1000
                
                # ç»Ÿè®¡æ•°æ®
                like_match = re.search(r'"digg_count"\s*:\s*(\d+)', script)
                if like_match:
                    like_count = int(like_match.group(1))
                
                comment_match = re.search(r'"comment_count"\s*:\s*(\d+)', script)
                if comment_match:
                    comment_count = int(comment_match.group(1))
                
                share_match = re.search(r'"share_count"\s*:\s*(\d+)', script)
                if share_match:
                    share_count = int(share_match.group(1))
                
                if title or video_url:
                    print(f"[æŠ–éŸ³] æˆåŠŸè§£æ: {title[:50]}")
                    print(f"[æŠ–éŸ³] ä½œè€…: {author}")
                    print(f"[æŠ–éŸ³] è§†é¢‘URL: {'å·²è·å–' if video_url else 'æ— '}")
                    
                    return {
                        "success": True,
                        "platform": "douyin",
                        "platform_name": "æŠ–éŸ³",
                        "video_id": video_id,
                        "title": title or f"æŠ–éŸ³è§†é¢‘ {video_id}",
                        "author": author or "æœªçŸ¥ä½œè€…",
                        "video_url": video_url,
                        "cover_url": cover_url,
                        "duration": duration,
                        "like_count": like_count,
                        "comment_count": comment_count,
                        "view_count": share_count,
                    }
            
            return self._error_response("æ— æ³•ä»é¡µé¢æå–è§†é¢‘æ•°æ®")
            
        except Exception as e:
            print(f"[æŠ–éŸ³] è§£æé”™è¯¯: {e}")
            return self._error_response(f"æŠ–éŸ³è§£æé”™è¯¯: {str(e)}")
    
    def get_video_info(self, url: str) -> Dict[str, Any]:
        """
        è·å–è§†é¢‘ä¿¡æ¯
        """
        if not yt_dlp:
            return self._error_response("yt-dlp æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install yt-dlp")
        
        if not url:
            return self._error_response("è¯·æä¾›è§†é¢‘é“¾æ¥")
        
        platform_key, platform_name = self.detect_platform(url)
        
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'extract_flat': False,
            'skip_download': True,
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
            },
        }
        
        # æŠ–éŸ³éœ€è¦ cookies è®¤è¯
        if platform_key == 'douyin':
            ydl_opts['cookiesfrombrowser'] = ('chrome',)
        
        try:
            print(f"[{platform_name}] æ­£åœ¨è§£æ: {url}")
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                
                if not info:
                    return self._error_response("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")
                
                # æå–è§†é¢‘ URL
                video_url = self._extract_best_video_url(info)
                
                return {
                    "success": True,
                    "platform": platform_key,
                    "platform_name": platform_name,
                    "video_id": info.get('id', str(int(time.time()))),
                    "title": info.get('title', info.get('description', 'æœªçŸ¥æ ‡é¢˜'))[:200],
                    "author": info.get('uploader', info.get('channel', info.get('creator', 'æœªçŸ¥ä½œè€…'))),
                    "video_url": video_url,
                    "cover_url": info.get('thumbnail', ''),
                    "duration": info.get('duration', 0),
                    "like_count": info.get('like_count', 0),
                    "view_count": info.get('view_count', 0),
                    "comment_count": info.get('comment_count', 0),
                }
                
        except Exception as e:
            error_msg = str(e)
            print(f"[{platform_name}] è§£æå¤±è´¥: {error_msg}")
            
            # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            if 'login' in error_msg.lower() or 'private' in error_msg.lower():
                return self._error_response(f"è¯¥è§†é¢‘å¯èƒ½æ˜¯ç§å¯†å†…å®¹æˆ–éœ€è¦ç™»å½•æ‰èƒ½æŸ¥çœ‹")
            elif 'not found' in error_msg.lower() or '404' in error_msg:
                return self._error_response(f"è§†é¢‘ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤")
            else:
                return self._error_response(f"è§£æå¤±è´¥: {error_msg[:100]}")
    
    def _extract_best_video_url(self, info: Dict) -> str:
        """ä» yt-dlp ä¿¡æ¯ä¸­æå–æœ€ä½³è§†é¢‘ URL"""
        # ä¼˜å…ˆä½¿ç”¨ url å­—æ®µ
        if info.get('url'):
            return info['url']
        
        # ä» formats ä¸­é€‰æ‹©æœ€ä½³
        formats = info.get('formats', [])
        if not formats:
            return ''
        
        # ä¼˜å…ˆé€‰æ‹© mp4 æ ¼å¼ï¼Œæ— æ°´å°
        for fmt in reversed(formats):
            if fmt.get('ext') == 'mp4' and fmt.get('url'):
                url = fmt['url']
                # è·³è¿‡å¸¦æ°´å°çš„
                if 'wm' not in url.lower():
                    return url
        
        # å›é€€åˆ°ä»»æ„ mp4
        for fmt in reversed(formats):
            if fmt.get('ext') == 'mp4' and fmt.get('url'):
                return fmt['url']
        
        # å›é€€åˆ°ä»»æ„æ ¼å¼
        for fmt in reversed(formats):
            if fmt.get('url'):
                return fmt['url']
        
        return ''
    
    @staticmethod
    def _decode_unicode_text(text: str) -> str:
        """æ­£ç¡®è§£ç åŒ…å« \\uXXXX çš„æ–‡æœ¬"""
        try:
            # æ›¿æ¢ \uXXXX ä¸ºå®é™…å­—ç¬¦
            def replace_unicode(match):
                return chr(int(match.group(1), 16))
            return re.sub(r'\\u([0-9a-fA-F]{4})', replace_unicode, text)
        except Exception:
            return text
    
    def download_video(self, url: str, filename: Optional[str] = None) -> Optional[str]:
        """
        ä¸‹è½½è§†é¢‘
        æ”¯æŒä¼ å…¥åˆ†äº«æ–‡æœ¬ï¼Œä¼šè‡ªåŠ¨æå– URL
        """
        if not url:
            return None
        
        # ä»åˆ†äº«æ–‡æœ¬ä¸­æå– URL
        extracted_url = self.extract_url_from_text(url)
        if not extracted_url:
            print("æ— æ³•ä»æ–‡æœ¬ä¸­æå– URL")
            return None
        url = extracted_url
        
        if not yt_dlp:
            print("yt-dlp æœªå®‰è£…")
            return None
        
        platform_key, platform_name = self.detect_platform(url)
        
        # ç”Ÿæˆæ–‡ä»¶å
        if not filename:
            timestamp = int(time.time())
            filename = f"{platform_key}_{timestamp}_{uuid.uuid4().hex[:8]}.mp4"
        
        # å¤„ç†è·¯å¾„
        if os.path.dirname(filename):
            filepath = filename
        else:
            filepath = os.path.join(self.download_dir, filename)
        
        if not filepath.endswith('.mp4'):
            filepath = filepath + '.mp4'
        
        ydl_opts = {
            'quiet': False,
            'no_warnings': False,
            'outtmpl': filepath.replace('.mp4', '') + '.%(ext)s',
            'format': 'best[ext=mp4]/best',
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept-Language': 'en-US,en;q=0.9',
                'Referer': url,
            },
            'retries': 3,
            'fragment_retries': 3,
        }
        
        # æŠ–éŸ³ä½¿ç”¨ç›´æ¥ä¸‹è½½è§†é¢‘ URL
        if platform_key == 'douyin':
            # å…ˆè§£æè·å–ç›´æ¥è§†é¢‘URLï¼Œç”¨ requests ç›´æ¥ä¸‹è½½
            douyin_info = self._get_douyin_video_info(url)
            if douyin_info.get('success') and douyin_info.get('video_url'):
                try:
                    video_direct_url = douyin_info['video_url']
                    print(f"[æŠ–éŸ³] ä½¿ç”¨æ— æ°´å°URLä¸‹è½½: {video_direct_url[:80]}...")
                    
                    # å…ˆè·å–é‡å®šå‘åçš„çœŸå®ä¸‹è½½åœ°å€
                    if _has_curl_cffi:
                        session = cffi_requests.Session(impersonate='chrome120')
                        # å…ˆè¯·æ±‚è·å–é‡å®šå‘åœ°å€
                        head_resp = session.get(video_direct_url, allow_redirects=True, timeout=30)
                        real_url = str(head_resp.url)
                        content_length = len(head_resp.content)
                        
                        if content_length > 0:
                            # ç›´æ¥å†™å…¥å·²è·å–çš„å†…å®¹
                            print(f"[æŠ–éŸ³] æ–‡ä»¶å¤§å°: {content_length / 1024 / 1024:.1f} MB")
                            with open(filepath, 'wb') as f:
                                f.write(head_resp.content)
                        else:
                            print(f"[æŠ–éŸ³] ä½¿ç”¨é‡å®šå‘åœ°å€ä¸‹è½½: {real_url[:80]}...")
                            resp = session.get(real_url, timeout=300)
                            with open(filepath, 'wb') as f:
                                f.write(resp.content)
                    else:
                        import requests as std_requests
                        resp = std_requests.get(video_direct_url, 
                            allow_redirects=True, 
                            timeout=300,
                            headers={'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)'},
                            stream=True
                        )
                        with open(filepath, 'wb') as f:
                            for chunk in resp.iter_content(chunk_size=65536):
                                if chunk:
                                    f.write(chunk)
                    
                    if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
                        file_size = os.path.getsize(filepath) / 1024 / 1024
                        print(f"[æŠ–éŸ³] ä¸‹è½½æˆåŠŸ: {filepath} ({file_size:.1f} MB)")
                        return os.path.basename(filepath)
                    else:
                        print(f"[æŠ–éŸ³] ä¸‹è½½æ–‡ä»¶ä¸ºç©º")
                        return None
                except Exception as e:
                    print(f"[æŠ–éŸ³] ç›´æ¥ä¸‹è½½å¤±è´¥: {e}")
                    return None
            else:
                print(f"[æŠ–éŸ³] æ— æ³•è·å–è§†é¢‘URL")
                return None
        
        try:
            print(f"[{platform_name}] æ­£åœ¨ä¸‹è½½: {url}")
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])
            
            # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
            import glob
            base_path = filepath.replace('.mp4', '')
            found_files = glob.glob(base_path + '.*')
            
            for found_file in found_files:
                if os.path.exists(found_file) and os.path.getsize(found_file) > 0:
                    print(f"[{platform_name}] ä¸‹è½½æˆåŠŸ: {found_file}")
                    return os.path.basename(found_file)
            
            print(f"[{platform_name}] æœªæ‰¾åˆ°ä¸‹è½½æ–‡ä»¶")
            return None
            
        except Exception as e:
            print(f"[{platform_name}] ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def _error_response(self, error: str) -> Dict[str, Any]:
        """ç”Ÿæˆé”™è¯¯å“åº”"""
        return {
            "success": False,
            "error": error,
        }
    
    def process_url(self, url: str) -> Dict[str, Any]:
        """
        å¤„ç† URL - ä¸»å…¥å£æ–¹æ³•
        æ”¯æŒç›´æ¥ä¼ å…¥åˆ†äº«æ–‡æœ¬ï¼Œä¼šè‡ªåŠ¨æå– URL
        """
        if not url:
            return self._error_response("è¯·æä¾›è§†é¢‘é“¾æ¥")
        
        # ä»åˆ†äº«æ–‡æœ¬ä¸­æå– URL
        extracted_url = self.extract_url_from_text(url)
        
        if not extracted_url:
            return self._error_response("æ— æ³•ä»æ–‡æœ¬ä¸­æå–è§†é¢‘é“¾æ¥")
        
        platform_key, platform_name = self.detect_platform(extracted_url)
        
        if platform_key == 'unknown':
            return self._error_response("æ— æ³•è¯†åˆ«è¯¥é“¾æ¥ï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„å¹³å°")
        
        # æŠ–éŸ³ä½¿ç”¨ç§»åŠ¨ç«¯é¡µé¢è§£æï¼ˆç»•è¿‡ yt-dlp cookies é—®é¢˜ï¼‰
        if platform_key == 'douyin':
            print(f"[{platform_name}] ä½¿ç”¨ç§»åŠ¨ç«¯é¡µé¢è§£æ")
            info = self._get_douyin_video_info(extracted_url)
            
            if info.get('success'):
                return {
                    "success": True,
                    "platform": platform_key,
                    "platform_name": platform_name,
                    "video_id": info.get('video_id', 'unknown'),
                    "video_info": {
                        "title": info.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                        "author": info.get('author', 'æœªçŸ¥ä½œè€…'),
                        "video_url": info.get('video_url', ''),
                        "cover_url": info.get('cover_url', ''),
                        "duration": info.get('duration', 0),
                        "like_count": info.get('like_count', 0),
                        "view_count": info.get('view_count', 0),
                        "comment_count": info.get('comment_count', 0),
                    },
                    "has_download_url": bool(info.get('video_url')),
                }
            else:
                return self._error_response(info.get('error', 'æŠ–éŸ³è§£æå¤±è´¥'))
        
        # å…¶ä»–å¹³å°ä½¿ç”¨ yt-dlp
        info = self.get_video_info(extracted_url)
        
        if not info.get('success'):
            return info
        
        return {
            "success": True,
            "platform": platform_key,
            "platform_name": platform_name,
            "video_id": info.get('video_id', 'unknown'),
            "video_info": {
                "title": info.get('title', 'æœªçŸ¥æ ‡é¢˜'),
                "author": info.get('author', 'æœªçŸ¥ä½œè€…'),
                "video_url": info.get('video_url', ''),
                "cover_url": info.get('cover_url', ''),
                "duration": info.get('duration', 0),
                "like_count": info.get('like_count', 0),
                "view_count": info.get('view_count', 0),
                "comment_count": info.get('comment_count', 0),
            },
            "has_download_url": bool(info.get('video_url')),
        }


# å•ä¾‹å®ä¾‹
universal_downloader = UniversalDownloader()
